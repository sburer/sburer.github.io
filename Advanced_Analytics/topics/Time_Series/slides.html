<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Samuel Burer">
  <title>Time Series</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="http://lab.hakim.se/reveal-js/css/reveal.css">
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="http://lab.hakim.se/reveal-js/css/theme/sky.css" id="theme">
  <link rel="stylesheet" href="../sburer.css"/>
  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? 'http://lab.hakim.se/reveal-js/css/print/pdf.css' : 'http://lab.hakim.se/reveal-js/css/print/paper.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>
  <!--[if lt IE 9]>
  <script src="http://lab.hakim.se/reveal-js/lib/js/html5shiv.js"></script>
  <![endif]-->
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section id="title-slide">
  <h1 class="title">Time Series</h1>
  <p class="author">Samuel Burer</p>
  <p class="date">Last updated: January 29, 2019</p>
</section>

<section><section id="getting-started" class="title-slide slide level1"><h1>Getting Started</h1></section><section id="section" class="slide level2">
<h2></h2>
<p><strong>Recall</strong></p>
<ul>
<li><em>Cross-sectional data</em> is gathered at a single point in time</li>
<li>E.g., current employee and salary information</li>
<li>Regression is a tool to explain/predict dependent <span class="math inline"><em>Y</em></span> using independent <span class="math inline"><em>X</em><sub>1</sub>, …, <em>X</em><sub><em>m</em></sub></span></li>
<li>Specifically, our goal has been to explain variation in <span class="math inline"><em>Y</em></span> (in a statistically meaningful way)</li>
</ul>
</section><section id="section-1" class="slide level2">
<h2></h2>
<p><strong>Time series data</strong></p>
<ul>
<li>Data of the same type gathered at consistent intervals of time</li>
<li>E.g., monthly unit sales for a particular product</li>
</ul>
</section><section id="section-2" class="slide level2">
<h2></h2>
<p><img data-src="graphics/usmelec.png" /> </p>
</section><section id="section-3" class="slide level2">
<h2></h2>
<ul>
<li>With time series data, our goal will still be to explain variation in the data</li>
<li>However, time-series tools are different and include more than just regression</li>
<li>E.g., what can you do when you have only <span class="math inline"><em>Y</em></span> but no <span class="math inline"><em>X</em><sub><em>i</em></sub></span>?</li>
</ul>
</section><section id="section-4" class="slide level2">
<h2></h2>
<p><strong>Notation</strong></p>
<ul>
<li><span class="math inline"><em>Y</em></span> = a single column of time series data</li>
<li><span class="math inline"><em>Y</em><sub><em>t</em></sub></span> = value of <span class="math inline"><em>Y</em></span> at time <span class="math inline"><em>t</em></span></li>
<li>We often use <span class="math inline"><em>Y</em></span> and <span class="math inline"><em>Y</em><sub><em>t</em></sub></span> interchangeably</li>
</ul>
</section><section id="section-5" class="slide level2">
<h2></h2>
<p>Before formally analyzing Y, we should adjust for the effects of certain factors</p>
</section><section id="section-6" class="slide level2">
<h2></h2>
<ul>
<li>Stabilize variation of <span class="math inline"><em>Y</em></span> over time by logging <span class="math inline"><em>Y</em></span></li>
<li>Adjust prices for inflation (using CPI)</li>
<li>Adjust for lengths of months or number of business days in month</li>
<li>Etc.</li>
</ul>
</section><section id="section-7" class="slide level2">
<h2></h2>
<p><img data-src="graphics/log_usmelec.png" /> </p>
</section><section id="section-8" class="slide level2">
<h2></h2>
<p>We assume throughout these slides that <span class="math inline"><em>Y</em></span> has already been logged (if necessary)</p>
</section></section>
<section><section id="exploration" class="title-slide slide level1"><h1>Exploration</h1></section><section id="section-9" class="slide level2">
<h2></h2>
<p>Given series <span class="math inline"><em>Y</em><sub><em>t</em></sub></span>, we break it into several components…</p>
</section><section id="section-10" class="slide level2">
<h2></h2>
<p><strong>Trend component</strong></p>
<ul>
<li>Long-term increase or decrease in the data</li>
<li>Not necessarily linear</li>
<li>May “change direction”</li>
</ul>
</section><section id="section-11" class="slide level2">
<h2></h2>
<p><strong>Seasonal component</strong></p>
<ul>
<li>Influence by predictable seasonal factors</li>
<li>E.g., days of week, months, quarters</li>
<li>Always of a fixed and known frequency</li>
<li>Seasons are usually obvious…but be careful
<ul>
<li>E.g., do the Summer Olympics have a seasonal effect?</li>
</ul></li>
</ul>
</section><section id="section-12" class="slide level2">
<h2></h2>
<p><strong>Cyclic component</strong></p>
<ul>
<li>Influence by hard-to-predict, non-periodic, sometimes unknown factors (“business cycles”)</li>
<li>A cycle usually lasts several seasons</li>
<li>Hard to identify, but need to be aware</li>
<li>In fact, the cyclic component is often lumped in with the trend</li>
</ul>
</section><section id="section-13" class="slide level2">
<h2></h2>
<p><strong>Remainder component</strong></p>
<ul>
<li>Any variation in the series, which is not due to the trend, seasonal, or cyclical components</li>
<li>Also called “random” or “irregular”</li>
<li>Analogous to residuals/errors in regression</li>
</ul>
</section><section id="section-14" class="slide level2">
<h2></h2>
<p><strong>Additive decomposition model</strong></p>
<p><br /><span class="math display"><em>Y</em><sub><em>t</em></sub> = <em>T</em><sub><em>t</em></sub> + <em>S</em><sub><em>t</em></sub> + <em>C</em><sub><em>t</em></sub> + <em>R</em><sub><em>t</em></sub></span><br /></p>
</section><section id="section-15" class="slide level2">
<h2></h2>
<ul>
<li>Because cyclic is hard to separate from trend, it is typical to just write <span class="math inline"><em>Y</em><sub><em>t</em></sub> = <em>T</em><sub><em>t</em></sub> + <em>S</em><sub><em>t</em></sub> + <em>R</em><sub><em>t</em></sub></span> where <span class="math inline"><em>T</em><sub><em>t</em></sub></span> is the combined <em>trend-cycle</em> component</li>
<li>Some people even just say “trend” for the trend-cycle component</li>
</ul>
</section><section id="section-16" class="slide level2">
<h2></h2>
<p><img data-src="graphics/decomp_log_usmelec.png" /> </p>
</section><section id="section-17" class="slide level2">
<h2></h2>
<p><strong>Seasonally Adjusted Data</strong></p>
<ul>
<li>Sometimes it is useful to remove the seasonality from a time series</li>
<li>For example, when you’d like to make an “apples to apples” comparison between data points in different seasons</li>
<li><em>Seasonally adjusted</em> time series is <span class="math inline"><em>Y</em><sub><em>t</em></sub> − <em>S</em><sub><em>t</em></sub> = <em>T</em><sub><em>t</em></sub> + <em>R</em><sub><em>t</em></sub></span></li>
</ul>
</section><section id="section-18" class="slide level2">
<h2></h2>
<p><img data-src="graphics/seasadj1_log_usmelec.png" /> </p>
</section><section id="section-19" class="slide level2">
<h2></h2>
<p><img data-src="graphics/seasadj2_log_usmelec.png" /> </p>
</section><section id="section-20" class="slide level2">
<h2></h2>
<p><img data-src="graphics/decomp_ui.png" /> </p>
</section></section>
<section><section id="fitting-a-time-series" class="title-slide slide level1"><h1>Fitting a Time Series</h1></section><section id="section-21" class="slide level2">
<h2></h2>
<ul>
<li>Given single time series <span class="math inline"><em>Y</em><sub><em>t</em></sub></span></li>
<li>We will soon look at several methods for constructing a “best-fit” time series <span class="math inline"><em>F</em><sub><em>t</em></sub></span> for <span class="math inline"><em>Y</em><sub><em>t</em></sub></span></li>
<li>If <span class="math inline"><em>F</em><sub><em>t</em></sub></span> fits well, then we can use <span class="math inline"><em>F</em><sub><em>t</em></sub></span> to forecast</li>
</ul>
</section><section id="section-22" class="slide level2">
<h2></h2>
<ul>
<li>Define <span class="math inline"><em>E</em><sub><em>t</em></sub> = <em>Y</em><sub><em>t</em></sub> − <em>F</em><sub><em>t</em></sub></span> to be the residual (“error”) time series</li>
<li>Similar to the remainder component of the decomposition</li>
<li>The residual time series contains our model’s mistakes—in sequential order (!)</li>
</ul>
</section><section id="section-23" class="slide level2">
<h2></h2>
<ul>
<li>To understand the fit, we need to critique <span class="math inline"><em>E</em><sub><em>t</em></sub></span></li>
<li>Similar to critiquing the errors in a regression</li>
</ul>
</section><section id="stationary-time-series" class="slide level2">
<h2>Stationary Time Series</h2>
</section><section id="section-24" class="slide level2">
<h2></h2>
<p>A <em>stationary series</em> is “pure noise”, i.e., a series that:</p>
<ul>
<li>Has no trend-cycle</li>
<li>Has no seasonality</li>
<li>Is normally distributed with mean 0</li>
<li>Exhibits no <em>autocorrelation</em> (more in a moment…)</li>
</ul>
</section><section id="section-25" class="slide level2">
<h2></h2>
<p><img data-src="graphics/stationary.png" /> </p>
</section><section id="section-26" class="slide level2">
<h2></h2>
<p>Ideally <span class="math inline"><em>E</em><sub><em>t</em></sub></span> is a stationary series</p>
<p> </p>
<p><strong>But what is autocorrelation?</strong></p>
</section><section id="lags" class="slide level2">
<h2>Lags</h2>
</section><section id="section-27" class="slide level2">
<h2></h2>
<ul>
<li>For a given time series <span class="math inline"><em>Y</em><sub><em>t</em></sub></span>, the <em>backward lagged series</em> of lag <span class="math inline"><em>k</em></span>, denoted <span class="math inline"><em>Y</em><sub><em>t</em> − <em>k</em></sub></span>, is the copy of <span class="math inline"><em>Y</em><sub><em>t</em></sub></span>, which is <span class="math inline"><em>k</em></span> units of time behind <span class="math inline"><em>Y</em><sub><em>t</em></sub></span></li>
<li>“Present values of <span class="math inline"><em>Y</em><sub><em>t</em> − <em>k</em></sub></span> are past values of <span class="math inline"><em>Y</em><sub><em>t</em></sub></span>”</li>
</ul>
</section><section id="section-28" class="slide level2">
<h2></h2>
<table>
<thead>
<tr class="header">
<th><span class="math inline"><em>t</em></span></th>
<th><span class="math inline"><em>Y</em><sub><em>t</em></sub></span></th>
<th><span class="math inline"><em>Y</em><sub><em>t</em> − 1</sub></span></th>
<th><span class="math inline"><em>Y</em><sub><em>t</em> − 2</sub></span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>4</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>2</td>
<td>9</td>
<td>4</td>
<td></td>
</tr>
<tr class="odd">
<td>3</td>
<td>16</td>
<td>9</td>
<td>4</td>
</tr>
<tr class="even">
<td>4</td>
<td>25</td>
<td>16</td>
<td>9</td>
</tr>
<tr class="odd">
<td>5</td>
<td>36</td>
<td>25</td>
<td>16</td>
</tr>
<tr class="even">
<td>6</td>
<td>49</td>
<td>36</td>
<td>25</td>
</tr>
</tbody>
</table>
</section><section id="autocorrelation" class="slide level2">
<h2>Autocorrelation</h2>
</section><section id="section-29" class="slide level2">
<h2></h2>
<ul>
<li><em>Autocorrelation (AC)</em> at lag <span class="math inline"><em>k</em></span> is the correlation between <span class="math inline"><em>Y</em><sub><em>t</em></sub></span> and <span class="math inline"><em>Y</em><sub><em>t</em> − <em>k</em></sub></span></li>
<li>For example, seasonality can lead to (significant) autocorrelations</li>
<li>But AC is not just caused by seasonality</li>
</ul>
</section><section id="section-30" class="slide level2">
<h2></h2>
<p><img data-src="graphics/soda.png" /> </p>
</section><section id="section-31" class="slide level2">
<h2></h2>
<p><img data-src="graphics/acf_soda.png" /> </p>
</section><section id="section-32" class="slide level2">
<h2></h2>
<p><img data-src="graphics/cpi.png" /> </p>
</section><section id="section-33" class="slide level2">
<h2></h2>
<p><img data-src="graphics/acf_cpi.png" /> </p>
</section><section id="section-34" class="slide level2">
<h2></h2>
<ul>
<li>As mentioned, we want <span class="math inline"><em>E</em><sub><em>t</em></sub></span> to be stationary, in particular, with no AC</li>
<li>The point is that AC is a pattern in the residuals—a pattern, which we should try to account for</li>
</ul>
</section><section id="measures-of-total-error" class="slide level2">
<h2>Measures of Total Error</h2>
</section><section id="section-35" class="slide level2">
<h2></h2>
<p>There are several ways to measure the total error in the residual time series <span class="math inline"><em>E</em><sub><em>t</em></sub></span></p>
</section><section id="section-36" class="slide level2">
<h2></h2>
<p><strong>Errors in the original units</strong></p>
<ul>
<li>Mean error = ME = mean(<span class="math inline"><em>E</em><sub><em>t</em></sub></span>)</li>
<li>Root mean squared error = RMSE = sqrt(mean(<span class="math inline"><em>E</em><sub><em>t</em></sub><sup>2</sup></span>))
<ul>
<li>Similar to standard error in linear regression</li>
</ul></li>
<li>Mean absolute error = MAE = mean(<span class="math inline">|<em>E</em><sub><em>t</em></sub>|</span>)</li>
</ul>
</section><section id="section-37" class="slide level2">
<h2></h2>
<p><strong>Percentage errors:</strong> <span class="math inline"><em>p</em><sub><em>t</em></sub> = 100<em>E</em><sub><em>t</em></sub>/<em>Y</em><sub><em>t</em></sub></span></p>
<ul>
<li>Mean percentage error = MPE = mean(<span class="math inline"><em>p</em><sub><em>t</em></sub></span>)</li>
<li>Mean absolute percentage error = MAPE = mean(<span class="math inline">|<em>p</em><sub><em>t</em></sub>|</span>)</li>
</ul>
</section></section>
<section><section id="linear-regression" class="title-slide slide level1"><h1>Linear Regression</h1></section><section id="section-38" class="slide level2">
<h2></h2>
<ul>
<li>Can use linear regression for fitting <span class="math inline"><em>Y</em><sub><em>t</em></sub></span></li>
<li>Simply regress on…
<ul>
<li>time index <span class="math inline"><em>t</em></span></li>
<li>dummies for the seasons (only if seasonality is present)</li>
</ul></li>
</ul>
</section><section id="section-39" class="slide level2">
<h2></h2>
<p><img data-src="graphics/regression_cpi.png" /> </p>
</section><section id="section-40" class="slide level2">
<h2></h2>
<p><img data-src="graphics/regression_soda.png" /> </p>
</section><section id="section-41" class="slide level2">
<h2></h2>
<ul>
<li>Check the usual diagnostics</li>
<li>Plus look for AC in <span class="math inline"><em>E</em><sub><em>t</em></sub></span></li>
</ul>
</section><section id="section-42" class="slide level2">
<h2></h2>
<p><img data-src="graphics/acf_regression_cpi.png" /> </p>
</section><section id="section-43" class="slide level2">
<h2></h2>
<p><img data-src="graphics/acf_regression_soda.png" /> </p>
</section><section id="section-44" class="slide level2">
<h2></h2>
<ul>
<li>This simple regression method works well sometimes—but not always</li>
<li>If model is good, can forecast using the regression equation</li>
</ul>
</section></section>
<section><section id="exponential-smoothing" class="title-slide slide level1"><h1>Exponential Smoothing</h1></section><section id="section-45" class="slide level2">
<h2></h2>
<ul>
<li><em>Exponential smoothing</em> fits <span class="math inline"><em>Y</em><sub><em>t</em></sub></span> by using only <span class="math inline"><em>Y</em><sub><em>t</em></sub></span> itself</li>
<li>“Learn from past data”</li>
<li>Idea is to balance old observations against recent ones</li>
</ul>
</section><section id="section-46" class="slide level2">
<h2></h2>
<p><strong>Terminology</strong></p>
<ul>
<li>Level = long-term “height” of the series</li>
<li>Slope = shorter-term up-and-down movement of the series <!-- - Season = effects due to seasonality --></li>
</ul>
</section><section id="simple-exponential-smoothing" class="slide level2">
<h2>Simple Exponential Smoothing</h2>
</section><section id="section-47" class="slide level2">
<h2></h2>
<ul>
<li>Simple exponential smoothing (SES) is best suited for non-seasonal time series without much slope</li>
<li>Choose a smoothing constant <span class="math inline">0 ≤ <em>α</em> ≤ 1</span>
<ul>
<li><span class="math inline"><em>α</em> ≈ 0</span> means emphasize old data</li>
<li><span class="math inline"><em>α</em> ≈ 1</span> means emphasize new data</li>
</ul></li>
</ul>
</section><section id="section-48" class="slide level2">
<h2></h2>
<p><strong>SES</strong></p>
<ul>
<li>Start by setting <span class="math inline"><em>F</em><sub>2</sub> = <em>Y</em><sub>1</sub></span></li>
<li>Then for <span class="math inline"><em>t</em> = 2, 3, 4, ...</span></li>
</ul>
<p><br /><span class="math display"><em>F</em><sub><em>t</em></sub> = <em>α</em><em>Y</em><sub><em>t</em> − 1</sub> + (1 − <em>α</em>)<em>F</em><sub><em>t</em> − 1</sub></span><br /></p>
</section><section id="section-49" class="slide level2">
<h2></h2>
<p><img data-src="graphics/rain.png" /> </p>
</section><section id="section-50" class="slide level2">
<h2></h2>
<p><img data-src="graphics/ses_050_rain.png" /> </p>
</section><section id="section-51" class="slide level2">
<h2></h2>
<p><img data-src="graphics/ses_001_rain.png" /> </p>
</section><section id="section-52" class="slide level2">
<h2></h2>
<p><img data-src="graphics/ses_099_rain.png" /> </p>
</section><section id="other-types" class="slide level2">
<h2>Other Types</h2>
</section><section id="section-53" class="slide level2">
<h2></h2>
<ul>
<li>There are more sophisticated versions of exponential smoothing that also incorporate
<ul>
<li><span class="math inline">0 ≤ <em>β</em> ≤ 1</span> for slope</li>
<li><span class="math inline">0 ≤ <em>γ</em> ≤ 1</span> for seasonality</li>
</ul></li>
<li>But idea of trading off old and new data is the same</li>
</ul>
</section><section id="section-54" class="slide level2">
<h2></h2>
<ul>
<li>There are many choices for <span class="math inline"><em>α</em>, <em>β</em>, <em>γ</em></span></li>
<li>And every choice leads to a different <span class="math inline"><em>F</em><sub><em>t</em></sub></span></li>
<li>Which choice is best?</li>
</ul>
</section><section id="section-55" class="slide level2">
<h2></h2>
<ul>
<li>Software packages, e.g., R, can choose the optimal paramater values</li>
<li>We will use a function that minimizes AIC (Akaike’s Information Criterion)</li>
</ul>
</section></section>
<section><section id="arima" class="title-slide slide level1"><h1>ARIMA</h1></section><section id="section-56" class="slide level2">
<h2></h2>
<ul>
<li>Suppose you have tried:
<ul>
<li>Linear regression over <span class="math inline"><em>t</em></span> and seasons</li>
<li>Exponential smoothing</li>
</ul></li>
<li>And yet you still see autocorrelation in <span class="math inline"><em>E</em><sub><em>t</em></sub></span></li>
<li>Is there anything else you can do?</li>
</ul>
</section><section id="section-57" class="slide level2">
<h2></h2>
<p><strong>Two New Ideas</strong></p>
<ul>
<li>Autoregression</li>
<li>Differencing</li>
</ul>
</section><section id="autoregression" class="slide level2">
<h2>Autoregression</h2>
</section><section id="section-58" class="slide level2">
<h2></h2>
<ul>
<li>It is kind of surprising, but the lagged series <span class="math inline"><em>Y</em><sub><em>t</em> − 1</sub></span> often does a very good job of predicting <span class="math inline"><em>Y</em><sub><em>t</em></sub></span></li>
<li>Autoregression (“AR”) of order 1 = regressing <span class="math inline"><em>Y</em><sub><em>t</em></sub></span> on <span class="math inline"><em>Y</em><sub><em>t</em> − 1</sub></span></li>
</ul>
</section><section id="section-59" class="slide level2">
<h2></h2>
<p><img data-src="graphics/autoregression_cpi.png" /> </p>
</section><section id="section-60" class="slide level2">
<h2></h2>
<ul>
<li>Often, one lag is enough, but we can do more</li>
<li>AR of order <span class="math inline"><em>k</em></span> = regressing <span class="math inline"><em>Y</em><sub><em>t</em></sub></span> on <span class="math inline"><em>Y</em><sub><em>t</em> − 1</sub>, …, <em>Y</em><sub><em>t</em> − <em>k</em></sub></span></li>
</ul>
</section><section id="differencing" class="slide level2">
<h2>Differencing</h2>
</section><section id="section-61" class="slide level2">
<h2></h2>
<ul>
<li>Differencing is a type of transformation</li>
<li>Should be applied to the original time series before applying other techniques</li>
</ul>
</section><section id="section-62" class="slide level2">
<h2></h2>
<p>Differenced series at lag <span class="math inline"><em>k</em></span> is defined as:</p>
<p><br /><span class="math display"><em>D</em>(<em>k</em>)<sub><em>t</em></sub> = <em>Y</em><sub><em>t</em></sub> − <em>Y</em><sub><em>t</em> − <em>k</em></sub></span><br /></p>
</section><section id="section-63" class="slide level2">
<h2></h2>
<ul>
<li><span class="math inline"><em>D</em>(1)<sub><em>t</em></sub></span> is the most important in practice</li>
<li>But <span class="math inline"><em>D</em>(<em>k</em>)<sub><em>t</em></sub></span> comes in handy for handling seasonality, e.g., <span class="math inline"><em>D</em>(12)<sub><em>t</em></sub></span> when there are 12 seasons</li>
</ul>
</section><section id="section-64" class="slide level2">
<h2></h2>
<ul>
<li>You can even difference <span class="math inline"><em>D</em>(1)<sub><em>t</em></sub></span>, e.g., difference the differenced series</li>
<li>Admittedly, this gets complicated</li>
</ul>
</section><section id="section-65" class="slide level2">
<h2></h2>
<ul>
<li>It may not be obvious at first, but…</li>
<li>Forecasting <span class="math inline"><em>D</em>(1)<sub><em>t</em></sub></span> is usually as good as forecasting <span class="math inline"><em>Y</em><sub><em>t</em></sub></span> itself</li>
<li>E.g., predicing next month’s sales <em>versus</em> predicting the change from this month to the next</li>
</ul>
</section><section id="arima-1" class="slide level2">
<h2>ARIMA</h2>
</section><section id="section-66" class="slide level2">
<h2></h2>
<p>ARIMA = Autoregressive Integrated Moving Average</p>
<p> </p>
<ul>
<li>AR = regressing on one or more lags of <span class="math inline"><em>Y</em><sub><em>t</em></sub></span></li>
<li>I = one or more differencing transformations</li>
<li>MA = regression on moving averages of errors</li>
</ul>
<p> </p>
<p>(MA is out of scope for us)</p>
</section><section id="section-67" class="slide level2">
<h2></h2>
<p><strong>ARIMA(<span class="math inline"><em>p</em></span>, <span class="math inline"><em>d</em></span>, <span class="math inline"><em>q</em></span>) without seasonality</strong></p>
<ul>
<li><span class="math inline"><em>p</em></span> = order of lag</li>
<li><span class="math inline"><em>d</em></span> = levels of differencing</li>
<li><span class="math inline"><em>q</em></span> = order of moving average</li>
</ul>
</section><section id="section-68" class="slide level2">
<h2></h2>
<p><strong>ARIMA(<span class="math inline"><em>p</em></span>, <span class="math inline"><em>d</em></span>, <span class="math inline"><em>q</em></span>)(<span class="math inline"><em>P</em></span>, <span class="math inline"><em>D</em></span>, <span class="math inline"><em>Q</em></span>) with seasonality</strong></p>
<ul>
<li><span class="math inline"><em>P</em></span> = order of seasonal lag</li>
<li><span class="math inline"><em>D</em></span> = levels of seasonal differencing</li>
<li><span class="math inline"><em>Q</em></span> = order of seasonal moving average</li>
</ul>
</section></section>
<section><section id="regression-with-multiple-series" class="title-slide slide level1"><h1>Regression with Multiple Series</h1></section><section id="section-69" class="slide level2">
<h2></h2>
<ul>
<li>We can also use linear regression to put multiple independent time series into a single model
<ul>
<li>E.g., predict sales based on advertising spend</li>
</ul></li>
</ul>
</section><section id="section-70" class="slide level2">
<h2></h2>
<ul>
<li>This also allows us to capture cycles, interventions, and one-off situations using dummy variables
<ul>
<li>E.g., capture the effect of economic recessions</li>
</ul></li>
</ul>
</section><section id="section-71" class="slide level2">
<h2></h2>
<ul>
<li>The challenge comes with forecasting</li>
<li>Before you can forecast the dependent series, you have to forecast the independent series</li>
<li>Forecast error compounds quickly, making forecasts reliable only a few time periods into the future</li>
</ul>
</section></section>
    </div>
  </div>

  <script src="http://lab.hakim.se/reveal-js/lib/js/head.min.js"></script>
  <script src="http://lab.hakim.se/reveal-js/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Push each slide change to the browser history
        history: true,

        // Optional reveal.js plugins
        dependencies: [
          { src: 'http://lab.hakim.se/reveal-js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: 'http://lab.hakim.se/reveal-js/plugin/zoom-js/zoom.js', async: true },
          { src: 'http://lab.hakim.se/reveal-js/plugin/notes/notes.js', async: true }
        ]
      });
    </script>
    </body>
</html>
